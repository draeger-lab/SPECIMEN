{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50824c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from specimen.util import set_up\n",
    "import specimen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d4b745",
   "metadata": {},
   "source": [
    "# HowTo: Collect Data needed to run the workflow\n",
    "\n",
    "The workflow requires a set of data and database files to run correctly. The following abstract show what data is needed (or optional) and where to (potentially) get it from.\n",
    "\n",
    "----\n",
    "## Setting up a structure to save the data to\n",
    "*\"Tidiness is half the battle\"*: To easily keep track of which data is already there and which is still missin, construct a directory structure with one folder for each of the data(base) type that is needed and fill them step by step. This can be done via the tool by running the function `set_up.build_data_directories`. \n",
    "\n",
    "The following directory structure will be created:\n",
    "\n",
    "- your_folder_name/\n",
    "    - annotated_genomes/\n",
    "    - <span style=\"color:green\">BiGG-namespace/ </span>\n",
    "    - BioCyc/\n",
    "    - medium/\n",
    "    - <span style=\"color:green\">MetaNetX/ </span>\n",
    "    - pan-core-models/\n",
    "    - RefSeqs/\n",
    "    - template-models/\n",
    "    - universal-models/\n",
    "\n",
    "Most of the folder will be emtpy, however the functions already directly downloads the files needed in the <span style=\"color:green\">MetaNetX/ </span> and <span style=\"color:green\">BiGG-namespace/ </span> folders, meaning those two do not need further adjustment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54325e4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating directory structure...\n",
      "INFO:root:Downloading BiGG-namespace...\n",
      "INFO:root:Downloading MetaNetX...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory test_data_collection/annotated_genomes/ already exists.\n",
      "Directory test_data_collection/BiGG-namespace/ already exists.\n",
      "Directory test_data_collection/BioCyc/ already exists.\n",
      "Directory test_data_collection/RefSeqs/ already exists.\n",
      "Directory test_data_collection/medium/ already exists.\n",
      "Directory test_data_collection/MetaNetX/ already exists.\n",
      "Directory test_data_collection/pan-core-models/ already exists.\n",
      "Directory test_data_collection/template-models/ already exists.\n",
      "Directory test_data_collection/universal-models/ already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_data_collection/MetaNetX/chem_prop.tsv: 645MiB [04:02, 2.79MiB/s] \n",
      "test_data_collection/MetaNetX/chem_xref.tsv: 552MiB [03:29, 2.77MiB/s] \n",
      "test_data_collection/MetaNetX/reac_prop.tsv: 8.69MiB [00:03, 2.71MiB/s]\n",
      "test_data_collection/MetaNetX/reac_xref.tsv: 66.2MiB [00:25, 2.72MiB/s]\n"
     ]
    }
   ],
   "source": [
    "# enable logging for more verbose output\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "set_up.build_data_directories('your_folder_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae20a8d",
   "metadata": {},
   "source": [
    "----\n",
    "Next, the input for the remaining directories will be discussed.\n",
    "\n",
    "## template-models/\n",
    "As this workflow is based on a high-quality template, having template model is <span style=\"color:red\">required</span> and not optional. Either copy a template model into this folder or remember to adjust the configuration file accordingly (...).\n",
    "\n",
    "## annotated_genomes/\n",
    "For the workflow, two annotated genomes, either `.gbff` (NCBI annotation pipeline) or `.faa` (PROKKA annotation pipeline, are <span style=\"color:red\">required</span>. One from the same genome that was used to generate the template model and one for the genome that will be used to generate the new model.\n",
    "> note: if the PROKKA annotation pipeline was used for the new genome, keep the `.fna` file as well, as the whole genome is later needed as well\n",
    "\n",
    "## BioCyc/\n",
    "- smart table of reactions from BioCyc/MetaCyc\n",
    "- optional, used to check for directionality\n",
    "- columns needed: Reactions, EC-Number, KEGG reaction, METANETX, Reaction-Direction\n",
    "> the columns names are listed above, Reactions in that case means the reaction ID \n",
    "\n",
    "## medium/\n",
    "- default medium database already part of the package (no input required, see HowTo about handling media)\n",
    "- place to add / store additional (new) media\n",
    "- for more information, take a look at the HowTo..... notebook\n",
    "\n",
    "## pan-core-models/\n",
    "- optional, needed for analysis and/or gapfilling\n",
    "- see other notebook about building a pan-core model\n",
    "\n",
    "## universal-models/\n",
    "- optional, nedded for gapfilling if no 'big enough' pan-core model is available\n",
    "\n",
    "## RefSeqs/\n",
    "<span style=\"color:red\">required</span> for the second *DIAMOND* run in the extension step of the pipeline\n",
    "\n",
    "*DIAMOND* database\n",
    "- first, download a set of FASTA files that should be part of the database, e.g. in **faa** format, and collect then in one folder\n",
    "- use the function `create_DIAMOND_db_from_folder` to create a *DIAMOND* database file from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "specimen.util.util.create_DIAMOND_db_from_folder('/User/path/input/directory',\n",
    "                                                 '/User/Path/for/output/', \n",
    "                                                 name = 'database',\n",
    "                                                 extention = 'faa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02f9d83",
   "metadata": {},
   "source": [
    "NCBI mapping (genome locus tags against old locus tags, EC number etc.)\n",
    "- download the annotated genome files, ideally gbff, for the genomes used in the previous step\n",
    "- run the function `create_NCBIinfo_mapping` on the folder with the files to create the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99126a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "specimen.util.util.create_NCBIinfo_mapping('/User/path/input/directory',\n",
    "                                           '/User/Path/for/output/', \n",
    "                                            extention = 'gbff')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa21832",
   "metadata": {},
   "source": [
    "NCBI information files of the genomes\n",
    "- file is optional \n",
    "- has to be created manually\n",
    "    - simple CSV file with the following columns: NCBI genome, organism, locus_tag (start) and KEGG.organism\n",
    "    - the information of the first three columns can be taken from the previous two steps while for the last column the user needs to check, if the genomes have been entered into KEGG and have an organism identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bfcb1e",
   "metadata": {},
   "source": [
    "----\n",
    "## Creating a configuration file\n",
    "\n",
    "The final input needed for the pipeline is the configuration file, in which the parameters that will be used are stored.\n",
    "\n",
    "There are two types of configuration files:\n",
    "\n",
    "- basic: a smaller version that includes less parameters but is easier to complete\n",
    "- advanced: complete version, gives full control of all parameters to the user\n",
    "   \n",
    "A new template for either version can be downloaded either via a python script e.g. a notebook by using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13628f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_up.download_config(filename='./my_basic_config.yaml', type='basic')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de8978",
   "metadata": {},
   "source": [
    "or via the commandline tool:\n",
    "\n",
    "- default: `specimen setup config `\n",
    "- set type: `specimen setup config -t advanced`\n",
    "- set name: `specimen setup config -f new_config.yaml`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7ae43c",
   "metadata": {},
   "source": [
    "After downloading the default configuration files, open it and adjust the parameters as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee630a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
